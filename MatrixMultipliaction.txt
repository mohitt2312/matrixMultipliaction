1. Prepare the Java Code
MatrixMapper.java
This Mapper class emits matrix values with keys that help the Reducer compute the matrix product.

java
Copy code
import java.io.IOException;
import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Mapper;

public class MatrixMapper extends Mapper<Object, Text, Text, IntWritable> {

    private static final IntWritable value = new IntWritable();
    private Text key = new Text();

    @Override
    protected void map(Object key, Text value, Context context) throws IOException, InterruptedException {
        String[] parts = value.toString().split(",");
        String matrixType = parts[0]; // "A" or "B"
        int i = Integer.parseInt(parts[1]);
        int j = Integer.parseInt(parts[2]);
        int v = Integer.parseInt(parts[3]);

        if (matrixType.equals("A")) {
            // Matrix A: Emit key as (i, k) with value as A[i][k]
            for (int k = 0; k < B_COLUMNS; k++) {
                key.set(i + "," + k);
                value.set(v);
                context.write(key, value);
            }
        } else if (matrixType.equals("B")) {
            // Matrix B: Emit key as (k, j) with value as B[k][j]
            for (int k = 0; k < A_ROWS; k++) {
                key.set(k + "," + j);
                value.set(v);
                context.write(key, value);
            }
        }
    }
}
MatrixReducer.java
This Reducer class calculates the final matrix values by summing up the products.

java
Copy code
import java.io.IOException;
import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Reducer;

public class MatrixReducer extends Reducer<Text, IntWritable, Text, IntWritable> {

    private IntWritable result = new IntWritable();

    @Override
    protected void reduce(Text key, Iterable<IntWritable> values, Context context) throws IOException, InterruptedException {
        String[] indices = key.toString().split(",");
        int i = Integer.parseInt(indices[0]);
        int j = Integer.parseInt(indices[1]);

        int sum = 0;
        for (IntWritable value : values) {
            sum += value.get();
        }

        result.set(sum);
        context.write(new Text(i + "," + j), result);
    }
}
MatrixMultiplication.java
This is the driver class that sets up and runs the MapReduce job.

java
Copy code
import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Job;
import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;
import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;

public class MatrixMultiplication {

    public static void main(String[] args) throws Exception {
        if (args.length != 2) {
            System.err.println("Usage: MatrixMultiplication <input path> <output path>");
            System.exit(-1);
        }

        Configuration conf = new Configuration();
        Job job = Job.getInstance(conf, "Matrix Multiplication");

        job.setJarByClass(MatrixMultiplication.class);
        job.setMapperClass(MatrixMapper.class);
        job.setReducerClass(MatrixReducer.class);

        job.setOutputKeyClass(Text.class);
        job.setOutputValueClass(IntWritable.class);

        FileInputFormat.addInputPath(job, new Path(args[0]));
        FileOutputFormat.setOutputPath(job, new Path(args[1]));

        System.exit(job.waitForCompletion(true) ? 0 : 1);
    }
}
2. Compile and Package the Code
Compile your Java code and create a JAR file. Hereâ€™s how you can do it using Maven:

Create a Maven pom.xml file with the necessary dependencies.
xml
Copy code
<project xmlns="http://maven.apache.org/POM/4.0.0"
         xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
         xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/POM/4.0.0">
    <modelVersion>4.0.0</modelVersion>
    <groupId>com.example</groupId>
    <artifactId>matrix-multiplication</artifactId>
    <version>1.0-SNAPSHOT</version>
    <dependencies>
        <dependency>
            <groupId>org.apache.hadoop</groupId>
            <artifactId>hadoop-common</artifactId>
            <version>3.3.4</version>
        </dependency>
        <dependency>
            <groupId>org.apache.hadoop</groupId>
            <artifactId>hadoop-mapreduce-client-core</artifactId>
            <version>3.3.4</version>
        </dependency>
    </dependencies>
</project>
Build the JAR file:
bash
Copy code
mvn clean package
This will create a JAR file in the target directory (e.g., matrix-multiplication-1.0-SNAPSHOT.jar).

3. Upload Input Files to HDFS
Assuming you have matrix_a.txt and matrix_b.txt prepared, upload them to HDFS:

bash
Copy code
hdfs dfs -mkdir -p /user/hadoop/input
hdfs dfs -put matrix_a.txt /user/hadoop/input/
hdfs dfs -put matrix_b.txt /user/hadoop/input/
4. Run the MapReduce Job
Submit the job to Hadoop:

bash
Copy code
hadoop jar target/matrix-multiplication-1.0-SNAPSHOT.jar MatrixMultiplication /user/hadoop/input /user/hadoop/output
5. Check the Output
Once the job completes, check the output directory:

bash
Copy code
hdfs dfs -ls /user/hadoop/output
hdfs dfs -cat /user/hadoop/output/part-r-00000
